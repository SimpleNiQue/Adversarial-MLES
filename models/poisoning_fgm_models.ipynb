{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Layer\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_dataset, to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing loss and optimizer objects\n",
    "# for ART's TensorFlowV2Classifier wrapper class\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Defining a training step for TensorFlowV2Classifier\n",
    "def train_step(\n",
    "    model, \n",
    "    inputs, \n",
    "    targets\n",
    "    ):\n",
    "    # Record the forward pass\n",
    "    # and loss calculations in our model\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(inputs=inputs, training=True)\n",
    "        loss_value = loss(y_true=targets, y_pred=preds)\n",
    "\n",
    "    # Compute gradients with respect to the model's weights\n",
    "    grads = tape.gradient(\n",
    "        target=loss_value, \n",
    "        sources=model.trainable_variables)\n",
    "\n",
    "    # Apply gradients to the model's weights\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisoning data for the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "(train_images_original, train_labels_original), (test_images_original, test_labels_original), min, max = load_dataset(name=\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for poisoning a given dataset\n",
    "def poison_dataset(\n",
    "    clean_images, \n",
    "    clean_labels, \n",
    "    target_labels, \n",
    "    percent_poison\n",
    "    ):\n",
    "    # Creating copies of our clean images and labels\n",
    "    # Poisoned samples will be added to these copies\n",
    "    x_poison = clean_images.copy()\n",
    "    y_poison = clean_labels.copy()\n",
    "\n",
    "    # Indicating our source labels (as integers)\n",
    "    source_labels = np.arange(10)\n",
    "\n",
    "    # Defining a backdoor attack\n",
    "    backdoor_attack = PoisoningAttackBackdoor(perturbation=add_pattern_bd)    \n",
    "\n",
    "    # Iterating over our source labels and provided target labels\n",
    "    for (source_label, target_label) in (zip(source_labels, target_labels)):\n",
    "        # Calculating the number of clean labels that are equal to the\n",
    "        # current source label\n",
    "        num_labels = np.size(np.where(np.argmax(a=clean_labels, axis=1) == source_label))                \n",
    "\n",
    "        # Calculating the number of samples that should be poisoned from\n",
    "        # the current source labels\n",
    "        num_poison = round(percent_poison * num_labels)\n",
    "        \n",
    "        # Getting the images for the current clean label\n",
    "        source_images = clean_images[np.argmax(a=clean_labels, axis=1) == source_label]\n",
    "\n",
    "        # Randomly picking indices to poison\n",
    "        indices_to_be_poisoned = np.random.choice(\n",
    "            a=num_labels, \n",
    "            size=num_poison\n",
    "            )        \n",
    "\n",
    "        # Get the images for the current label that should be poisoned\n",
    "        images_to_be_poisoned = source_images[indices_to_be_poisoned].copy()        \n",
    "\n",
    "        # Converting the target label to a categorical\n",
    "        target_label = to_categorical(labels=(np.ones(shape=num_poison) * target_label), nb_classes=10)\n",
    "\n",
    "        # Poisoning the images and labels for the current label\n",
    "        poisoned_images, poisoned_labels = backdoor_attack.poison(\n",
    "            x=images_to_be_poisoned, \n",
    "            y=target_label\n",
    "            )\n",
    "\n",
    "        # Appending the poisoned images to our clean images\n",
    "        x_poison = np.append(\n",
    "            arr=x_poison, \n",
    "            values=poisoned_images, \n",
    "            axis=0\n",
    "            )\n",
    "\n",
    "        # Appending the poisoned labels to our clean labels\n",
    "        y_poison = np.append(\n",
    "            arr=y_poison, \n",
    "            values=poisoned_labels, \n",
    "            axis=0\n",
    "            )\n",
    "    \n",
    "    # Returning the poisoned samples and the poison indicator array\n",
    "    return x_poison, y_poison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining target labels (0, 1, 2, 3 ... 0)\n",
    "target_labels = (np.arange(10) + 1) % 10\n",
    "\n",
    "# Poisoning the training data\n",
    "percent_poison = .50\n",
    "(train_images, train_labels) = poison_dataset(\n",
    "    clean_images=train_images_original[:10000], \n",
    "    clean_labels=train_labels_original[:10000], \n",
    "    target_labels=target_labels, \n",
    "    percent_poison=percent_poison)\n",
    "\n",
    "# Poisoning the test data\n",
    "(test_images, test_labels) = poison_dataset(\n",
    "    clean_images=test_images_original, \n",
    "    clean_labels=test_labels_original,\n",
    "    target_labels=target_labels, \n",
    "    percent_poison=percent_poison)\n",
    "\n",
    "# Shuffling the training data\n",
    "num_train = train_images.shape[0]\n",
    "shuffled_indices = np.arange(num_train)\n",
    "np.random.shuffle(shuffled_indices)\n",
    "train_images = train_images[shuffled_indices]\n",
    "train_labels = train_labels[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model on the poisoned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a model with the Functional API\n",
    "def create_model():\n",
    "    # Defining and connecting the model's layers\n",
    "    input = tf.keras.layers.Input(shape=(28, 28, 1))    \n",
    "    x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(input)\n",
    "    x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=128, activation=\"relu\")(x)\n",
    "    output = Dense(units=10, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Initializing the model\n",
    "    model = tf.keras.models.Model(inputs=[input], outputs=[output])  \n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "        )   \n",
    "\n",
    "    # Returning the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 4s 38ms/step - loss: 1.6119 - accuracy: 0.4598\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0730 - accuracy: 0.5759\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.7955 - accuracy: 0.7013\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4296 - accuracy: 0.8825\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.2156 - accuracy: 0.9416\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1417 - accuracy: 0.9611\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0986 - accuracy: 0.9741\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0781 - accuracy: 0.9781\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0660 - accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0504 - accuracy: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b30ad0040>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating and training a victim classifier\n",
    "# with the poisoned data\n",
    "model_poisoned = create_model()\n",
    "model_poisoned.fit(\n",
    "    x=train_images, \n",
    "    y=train_labels, \n",
    "    epochs=10,\n",
    "    batch_size=1024\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the poisoned model\n",
    "model_poisoned.save(filepath=\"poisoned_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training vulnerable and robust models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "# Initializing a vulnerable classsifier\n",
    "# Wrapping our model in KerasClassifier\n",
    "vulnerable_classifier = TensorFlowV2Classifier(\n",
    "    model=create_model(),\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    loss_object=loss,\n",
    "    train_step=train_step\n",
    "    )\n",
    "\n",
    "# Initializing a robust classifier\n",
    "robust_classifier = TensorFlowV2Classifier(\n",
    "    model=create_model(),\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    loss_object=loss,\n",
    "    train_step=train_step\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the vulnerable classifier\n",
    "vulnerable_classifier.fit(\n",
    "    x=train_images_original[:10000], \n",
    "    y=train_labels_original[:10000], \n",
    "    nb_epochs=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the vulnerable classifier\n",
    "vulnerable_classifier._model.save(filepath=\"vulnerable_model_fgm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Fast Gradient Method attack\n",
    "attack_fgm = FastGradientMethod(\n",
    "    estimator=vulnerable_classifier, \n",
    "    eps=0.15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an adversarial trainer to train\n",
    "# a robust model\n",
    "trainer = AdversarialTrainer(\n",
    "    classifier=robust_classifier, \n",
    "    attacks=attack_fgm, \n",
    "    ratio=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precompute adv samples: 100%|██████████| 1/1 [00:04<00:00,  4.29s/it]\n",
      "Adversarial training epochs: 100%|██████████| 10/10 [00:19<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training the robust classifier\n",
    "trainer.fit(\n",
    "    x=train_images_original[:10000], \n",
    "    y=train_labels_original[:10000],\n",
    "    nb_epochs=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the robust model\n",
    "robust_classifier._model.save(filepath=\"robust_model_fgm.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f70919de02cd95c592d326227477d23447c62ed3e27fe887d4c4050715a0d7b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
