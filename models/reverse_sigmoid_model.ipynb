{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Layer\n",
    "from art.defences.postprocessor import ReverseSigmoid\n",
    "from art.attacks.extraction import CopycatCNN\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing loss and optimizer objects\n",
    "# for ART's TensorFlowV2Classifier wrapper class\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Defining a training step for TensorFlowV2Classifier\n",
    "def train_step(\n",
    "    model, \n",
    "    inputs, \n",
    "    targets\n",
    "    ):\n",
    "    # Record the forward pass\n",
    "    # and loss calculations in our model\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(inputs=inputs, training=True)\n",
    "        loss_value = loss(y_true=targets, y_pred=preds)\n",
    "\n",
    "    # Compute gradients with respect to the model's weights\n",
    "    grads = tape.gradient(\n",
    "        target=loss_value, \n",
    "        sources=model.trainable_variables)\n",
    "\n",
    "    # Apply gradients to the model's weights\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "(train_images_original, train_labels_original), (test_images_original, test_labels_original), min, max = load_dataset(name=\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting aside a subset of the source dataset for the original model\n",
    "train_images_victim = train_images_original[:50000]\n",
    "train_labels_victim = train_labels_original[:50000]\n",
    "\n",
    "# Using the rest of the source dataset for the stolen model\n",
    "train_images_stolen = train_images_original[50000:]\n",
    "train_labels_stolen = train_labels_original[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a postprocessor for comparison\n",
    "postprocessor = ReverseSigmoid(\n",
    "    beta=1.0, \n",
    "    gamma=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom TF Keras class that implements ART's Reverse Sigmoid postprocessing defense\n",
    "class ReverseSigmoidLayer(Layer):\n",
    "    # Layer constructor   \n",
    "    def __init__(self, beta, gamma, **kwargs):\n",
    "        super(ReverseSigmoidLayer, self).__init__(**kwargs)\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    # Method that defines the forward pass of the layer\n",
    "    def call(self, preds, training=None):\n",
    "        # Returning unprocessed inputs when training\n",
    "        if training:\n",
    "            return preds\n",
    "        \n",
    "        # Computing reverse sigmoid when not training\n",
    "        clip_min = 1e-9\n",
    "        clip_max = 1.0 - clip_min\n",
    "        \n",
    "        preds_clipped = tf.clip_by_value(t=preds, clip_value_min=clip_min, clip_value_max=clip_max)\n",
    "\n",
    "        if preds.shape[1] > 1:\n",
    "            perturbation_r = self.beta * (\n",
    "                self.sigmoid(z=(-self.gamma * tf.math.log(x=((1.0 - preds_clipped) / preds_clipped)))) - 0.5\n",
    "                )\n",
    "            preds_perturbed = preds - perturbation_r\n",
    "            preds_perturbed = tf.clip_by_value(t=preds_perturbed, clip_value_min=0.0, clip_value_max=1.0)\n",
    "            alpha = 1.0 / tf.math.reduce_sum(input_tensor=preds_perturbed, axis=-1, keepdims=True)\n",
    "            reverse_sigmoid = alpha * preds_perturbed\n",
    "        else:\n",
    "            preds_1 = preds\n",
    "            preds_2 = 1.0 - preds\n",
    "            \n",
    "            preds_clipped_1 = preds_clipped\n",
    "            preds_clipped_2 = 1.0 - preds_clipped\n",
    "\n",
    "            perturbation_r_1 = self.beta * (\n",
    "                self.sigmoid(z=(-self.gamma * tf.math.log(x=((1.0 - preds_clipped_1) / preds_clipped_1)))) - 0.5\n",
    "            )\n",
    "\n",
    "            perturbation_r_2 = self.beta * (\n",
    "                self.sigmoid(z=(-self.gamma * tf.math.log(x=((1.0 - preds_clipped_2) / preds_clipped_2)))) - 0.5\n",
    "            )\n",
    "\n",
    "            preds_perturbed_1 = preds_1 - perturbation_r_1\n",
    "            preds_perturbed_2 = preds_2 - perturbation_r_2\n",
    "\n",
    "            preds_perturbed_1 = tf.clip_by_value(t=preds_perturbed_1, clip_value_min=0.0, clip_value_max=1.0)\n",
    "            preds_perturbed_2 = tf.clip_by_value(t=preds_perturbed_2, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "            alpha = 1.0 / (preds_perturbed_1 + preds_perturbed_2)\n",
    "            reverse_sigmoid = alpha * preds_perturbed_1\n",
    "\n",
    "        return reverse_sigmoid\n",
    "        \n",
    "    # Method for getting layer config when saving model\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"beta\": self.beta,\n",
    "            \"gamma\": self.gamma,\n",
    "        })\n",
    "        return config          \n",
    "\n",
    "    # Method to compute standard sigmoid\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0 / (1.0 + tf.math.exp(x=-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a model with the Functional API\n",
    "def create_model():\n",
    "    # Defining and connecting the model's layers\n",
    "    input = tf.keras.layers.Input(shape=(28, 28, 1))    \n",
    "    x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(input)\n",
    "    x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=128, activation=\"relu\")(x)\n",
    "    output = Dense(units=10, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Initializing the model\n",
    "    model = tf.keras.models.Model(inputs=[input], outputs=[output])  \n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "        )   \n",
    "\n",
    "    # Returning the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def create_model():\\n    # Defining the model   \\n    model = tf.keras.models.Sequential([        \\n        Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)),\\n        Conv2D(filters=64, kernel_size=3, activation=\"relu\"),\\n        MaxPool2D(pool_size=2),        \\n        Flatten(),\\n        Dense(units=128, activation=\"relu\"),\\n        Dense(units=10, activation=\"softmax\")        \\n    ])\\n\\n    # Compiling the model\\n    model.compile(\\n        optimizer=\"adam\",\\n        loss=\"categorical_crossentropy\",\\n        metrics=[\"accuracy\"]\\n        )   \\n\\n    # Returning the model\\n    return model'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The same function but using the Sequential API\n",
    "\"\"\"def create_model():\n",
    "    # Defining the model   \n",
    "    model = tf.keras.models.Sequential([        \n",
    "        Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        Conv2D(filters=64, kernel_size=3, activation=\"relu\"),\n",
    "        MaxPool2D(pool_size=2),        \n",
    "        Flatten(),\n",
    "        Dense(units=128, activation=\"relu\"),\n",
    "        Dense(units=10, activation=\"softmax\")        \n",
    "    ])\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "        )   \n",
    "\n",
    "    # Returning the model\n",
    "    return model\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 10s 35ms/step - loss: 0.4994 - accuracy: 0.8635\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.1214 - accuracy: 0.9648\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.0690 - accuracy: 0.9788 0s - loss: 0.0702 - ac\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0501 - accuracy: 0.9852 0s - loss: 0.0514 - ac\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0406 - accuracy: 0.9877\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0330 - accuracy: 0.9901\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.0266 - accuracy: 0.9923\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0232 - accuracy: 0.9934\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0193 - accuracy: 0.9945 0s - loss: 0.0\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0149 - accuracy: 0.9957\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0125 - accuracy: 0.9965\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0101 - accuracy: 0.9973\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0078 - accuracy: 0.9979\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.0020 - accuracy: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a18182eb20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing and training the model\n",
    "victim_model = create_model()\n",
    "victim_model.fit(\n",
    "    x=train_images_victim,\n",
    "    y=train_labels_victim,\n",
    "    batch_size=1024,\n",
    "    epochs=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing our custom layer and linking it to the model's output\n",
    "protected_output = ReverseSigmoidLayer(beta=1.0, gamma=0.2)(victim_model.output)\n",
    "\n",
    "# Creating a new model with the custom layer on top while preserving the old model's weights\n",
    "protected_model = tf.keras.models.Model(inputs=[victim_model.input], outputs=[protected_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Viewing the victim model's architecture\n",
    "victim_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " reverse_sigmoid_layer (Reve  (None, 10)               0         \n",
      " rseSigmoidLayer)                                                \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Viewing the protected model's architecture\n",
    "protected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the unprotected model\n",
    "classifier_unprotected = TensorFlowV2Classifier(\n",
    "    model=victim_model,\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    loss_object=loss,\n",
    "    train_step=train_step\n",
    ")\n",
    "\n",
    "# Wrapping the unprotected model\n",
    "# and adding ART's postprocessing defense to it\n",
    "classifier_protected = TensorFlowV2Classifier(\n",
    "    model=victim_model,\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    loss_object=loss,\n",
    "    train_step=train_step,\n",
    "    postprocessing_defences=postprocessor\n",
    ")\n",
    "\n",
    "# Wrapping the custom protected model\n",
    "# without adding ART's postprocessing defense\n",
    "classifier_protected_custom = TensorFlowV2Classifier(\n",
    "    model=protected_model,\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    loss_object=loss,\n",
    "    train_step=train_step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the probabilistic \"neural net thief\" object\n",
    "# that will try to steal the unprotected classifier\n",
    "copycat_cnn_unprotected_probabilistic = CopycatCNN(\n",
    "    batch_size_fit=256,\n",
    "    batch_size_query=256,\n",
    "    nb_epochs=10,\n",
    "    nb_stolen=len(train_images_stolen),\n",
    "    use_probability=True,\n",
    "    classifier=classifier_unprotected    \n",
    "    )\n",
    "\n",
    "# Creating the probabilistic \"neural net thief\" object\n",
    "# that will try to steal the protected classifier\n",
    "copycat_cnn_protected_probabilistic = CopycatCNN(\n",
    "    batch_size_fit=256,\n",
    "    batch_size_query=256,\n",
    "    nb_epochs=10,\n",
    "    nb_stolen=len(train_images_stolen),\n",
    "    use_probability=True,\n",
    "    classifier=classifier_protected\n",
    "    )\n",
    "\n",
    "# Creating the probabilistic \"neural net thief\" object\n",
    "# that will try to steal the protected custom classifier\n",
    "copycat_cnn_protected_probabilistic_custom = CopycatCNN(\n",
    "    batch_size_fit=256,\n",
    "    batch_size_query=256,\n",
    "    nb_epochs=10,\n",
    "    nb_stolen=len(train_images_stolen),\n",
    "    use_probability=True,\n",
    "    classifier=classifier_protected_custom\n",
    "    )\n",
    "\n",
    "# Initializing base models that will be trained by the model extractor\n",
    "# The unprotected model\n",
    "model_stolen_unprotected = TensorFlowV2Classifier(\n",
    "    model=create_model(),\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    loss_object=loss,\n",
    "    train_step=train_step\n",
    "    )\n",
    "\n",
    "# The model protected by ART's Reverse Sigmoid\n",
    "model_stolen_protected = TensorFlowV2Classifier(\n",
    "    model=create_model(),\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    loss_object=loss,\n",
    "    train_step=train_step\n",
    "    )\n",
    "\n",
    "# The model protected by the custom Reverse Sigmoid layer\n",
    "model_stolen_protected_custom = TensorFlowV2Classifier(\n",
    "    model=create_model(),\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    loss_object=loss,\n",
    "    train_step=train_step\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the unprotected model\n",
    "classifier_stolen_unprotected_probabilistic = copycat_cnn_unprotected_probabilistic.extract(\n",
    "    x=train_images_stolen, \n",
    "    y=train_labels_stolen, \n",
    "    thieved_classifier=model_stolen_unprotected\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tigra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\art\\defences\\postprocessor\\reverse_sigmoid.py:75: RuntimeWarning: divide by zero encountered in log\n",
      "  perturbation_r = self.beta * (sigmoid(-self.gamma * np.log((1.0 - preds_clipped) / preds_clipped)) - 0.5)\n"
     ]
    }
   ],
   "source": [
    "# Extracting the protected classifier\n",
    "classifier_stolen_protected_probabilistic = copycat_cnn_protected_probabilistic.extract(\n",
    "    x=train_images_stolen, \n",
    "    y=train_labels_stolen, \n",
    "    thieved_classifier=model_stolen_protected\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the protected custom classifier\n",
    "classifier_stolen_protected_probabilistic_custom = copycat_cnn_protected_probabilistic_custom.extract(\n",
    "    x=train_images_stolen, \n",
    "    y=train_labels_stolen, \n",
    "    thieved_classifier=model_stolen_protected_custom\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0408 - accuracy: 0.9890\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0652 - accuracy: 0.9808\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.3025 - accuracy: 0.1135\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.3025 - accuracy: 0.1135\n",
      "\n",
      "------ TEST METRICS, ORIGINAL VS PROBABILISTIC STOLEN MODELS ------\n",
      "\n",
      "\n",
      "------ TEST LOSS ------\n",
      "\n",
      "Original model: 0.04\n",
      "Stolen unprotected model: 0.07\n",
      "Stolen protected model: 2.30\n",
      "Stolen protected custom model: 2.30\n",
      "\n",
      "------ TEST ACCURACY ------\n",
      "\n",
      "Original model: 0.99\n",
      "Stolen unprotected model: 0.98\n",
      "Stolen protected model: 0.11\n",
      "Stolen protected custom model: 0.11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance of the victim model and the stolen models\n",
    "score_victim = classifier_unprotected._model.evaluate(x=test_images_original, y=test_labels_original)\n",
    "score_stolen_unprotected_probabilistic = classifier_stolen_unprotected_probabilistic._model.evaluate(x=test_images_original, y=test_labels_original)\n",
    "score_stolen_protected_probabilistic = classifier_stolen_protected_probabilistic._model.evaluate(x=test_images_original, y=test_labels_original)\n",
    "score_stolen_protected_probabilistic_custom = classifier_stolen_protected_probabilistic_custom._model.evaluate(x=test_images_original, y=test_labels_original)\n",
    "\n",
    "# Comparing test losses\n",
    "print(\"\\n------ TEST METRICS, ORIGINAL VS PROBABILISTIC STOLEN MODELS ------\\n\\n\")\n",
    "print(\"------ TEST LOSS ------\\n\")\n",
    "print(f\"Original model: {score_victim[0]:.2f}\\n\" \n",
    "      f\"Stolen unprotected model: {score_stolen_unprotected_probabilistic[0]:.2f}\\n\"\n",
    "      f\"Stolen protected model: {score_stolen_protected_probabilistic[0]:.2f}\\n\"\n",
    "      f\"Stolen protected custom model: {score_stolen_protected_probabilistic_custom[0]:.2f}\\n\")\n",
    "\n",
    "# Comparing test accuracies\n",
    "print(\"------ TEST ACCURACY ------\\n\")\n",
    "print(f\"Original model: {score_victim[1]:.2f}\\n\" \n",
    "      f\"Stolen unprotected model: {score_stolen_unprotected_probabilistic[1]:.2f}\\n\"\n",
    "      f\"Stolen protected model: {score_stolen_protected_probabilistic[1]:.2f}\\n\"\n",
    "      f\"Stolen protected custom model: {score_stolen_protected_probabilistic_custom[1]:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Output probabilities ---\n",
      "\n",
      "[[2.7468112e-15 1.8481106e-12 1.2033476e-09 5.2852425e-08 1.6848592e-16\n",
      "  7.7248734e-14 5.5748515e-22 9.9999988e-01 1.4328472e-10 1.1050387e-07]\n",
      " [1.1688788e-13 5.0403987e-11 1.0000000e+00 2.3392673e-16 5.9806787e-19\n",
      "  8.9342873e-21 5.3660982e-12 6.5156306e-20 7.7604608e-15 9.2375143e-14]\n",
      " [2.3782047e-09 9.9999833e-01 3.4241248e-09 2.0667263e-11 1.2605947e-06\n",
      "  2.1213259e-11 2.2180614e-10 4.2062942e-07 2.2162581e-08 4.7198332e-11]\n",
      " [9.9999905e-01 8.5247933e-13 2.2508762e-09 1.4310031e-13 3.0353983e-12\n",
      "  6.0558954e-11 9.9701549e-07 6.5476090e-11 1.2894335e-11 2.6122401e-11]\n",
      " [1.0913101e-16 1.5779389e-15 1.1723524e-14 1.4936533e-17 1.0000000e+00\n",
      "  2.0704192e-18 5.4001573e-15 1.5701909e-14 2.8311672e-12 1.1672593e-09]] \n",
      "\n",
      "\n",
      "--- Class predictions ---\n",
      "\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Viewing the predictions of the victim model (standard probabilities)\n",
    "preds = victim_model.predict(x=test_images_original[:5])\n",
    "\n",
    "print(\"--- Output probabilities ---\\n\")\n",
    "print(preds, \"\\n\\n\")\n",
    "\n",
    "print(\"--- Class predictions ---\\n\")\n",
    "print(tf.math.argmax(input=preds, axis=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Protected output probabilities ---\n",
      "\n",
      "[[0.09973355 0.09973355 0.09961436 0.09597486 0.09973355 0.09973355\n",
      "  0.09973355 0.11109942 0.09973355 0.09491012]\n",
      " [0.09967895 0.09967895 0.10288944 0.09967895 0.09967895 0.09967895\n",
      "  0.09967895 0.09967895 0.09967895 0.09967895]\n",
      " [0.09982257 0.11720216 0.09953831 0.10042316 0.09080638 0.10042316\n",
      "  0.10042316 0.09321153 0.09772635 0.10042316]\n",
      " [0.11470099 0.09942506 0.09887123 0.09942506 0.09942506 0.09942506\n",
      "  0.09045236 0.09942506 0.09942506 0.09942506]\n",
      " [0.09968884 0.09968884 0.09968884 0.09968884 0.10289965 0.09968884\n",
      "  0.09968884 0.09968884 0.09968884 0.09958959]] \n",
      "\n",
      "\n",
      "--- Class predictions ---\n",
      "\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Viewing the predictions of the model protected by the custom Reverse Sigmoid\n",
    "protected_preds = protected_model.predict(x=test_images_original[:5])\n",
    "\n",
    "print(\"--- Protected output probabilities ---\\n\")\n",
    "print(protected_preds, \"\\n\\n\")\n",
    "\n",
    "print(\"--- Class predictions ---\\n\")\n",
    "print(tf.math.argmax(input=protected_preds, axis=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Protected output probabilities (ART's Reverse Sigmoid) ---\n",
      "\n",
      "[[0.09973355 0.09973355 0.09961436 0.09597485 0.09973355 0.09973355\n",
      "  0.09973355 0.11109942 0.09973355 0.09491012]\n",
      " [0.09967895 0.09967895 0.10288944 0.09967895 0.09967895 0.09967895\n",
      "  0.09967895 0.09967895 0.09967895 0.09967895]\n",
      " [0.09982257 0.11720216 0.09953831 0.10042316 0.09080638 0.10042316\n",
      "  0.10042316 0.09321153 0.09772635 0.10042316]\n",
      " [0.11470099 0.09942506 0.09887123 0.09942506 0.09942506 0.09942506\n",
      "  0.09045236 0.09942506 0.09942506 0.09942506]\n",
      " [0.09968884 0.09968884 0.09968884 0.09968884 0.10289965 0.09968884\n",
      "  0.09968884 0.09968884 0.09968884 0.09958959]] \n",
      "\n",
      "\n",
      "--- Class predictions ---\n",
      "\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Passing the victim model's output through ART's Reverse Sigmoid\n",
    "# to make sure that the custom layer has the same output\n",
    "print(\"--- Protected output probabilities (ART's Reverse Sigmoid) ---\\n\")\n",
    "print(postprocessor(preds), \"\\n\\n\")\n",
    "\n",
    "print(\"--- Class predictions ---\\n\")\n",
    "print(tf.math.argmax(input=postprocessor(preds), axis=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Saving the protected model with the custom output\n",
    "protected_model.save(filepath=\"postprocessed_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f70919de02cd95c592d326227477d23447c62ed3e27fe887d4c4050715a0d7b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
